---
title: "p8105_hw5_nc2710"
author: "Nicole Comfort"
date: "11/8/2018"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

devtools::install_github("thomasp85/patchwork")

library(tidyverse)
library(ggplot2)
library(ggridges)
library(readxl)
library(dplyr)
library(janitor)
library(patchwork)
library(viridis)
library(rvest)
library(purrr)

# set options for figures
knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "95%"
)

theme_set(theme_bw() + theme(legend.position = "bottom"))
```

## Problem 1 

The hw5_data zip file contains data from a longitudinal study that included a control arm and an experimental arm. Data for each participant is included in a separate file, and file names include the subject ID and arm (10 subjects per arm). 

The code below creates a tidy dataframe containing data from all participants, including the subject ID, arm, and observations over time:

```{r import and tidy data}

# start with a dataframe containing all file names; the list.files function will help 

# Iterate over file names and read in data for each subject using purrr::map and saving the result as a new variable in the dataframe

# Tidy the result; manipulate file names to include control arm and subject ID, make sure weekly observations are “tidy”, and do any other tidying that’s necessary


```

Describe resulting dataframe using inline code. 

Make a spaghetti plot showing observations on each subject over time, and comment on differences between groups.

```{r spaghetti plot}



```

## Problem 2 

The Washington Post has gathered data on homicides in 50 large U.S. cities and made the data available through a GitHub repository. The code below loads the data and executes some data manipulation:  

```{r import homicide data}

read_csv(file = "./data/homicide-data.csv") %>% # import dataset
  janitor::clean_names() %>% # clean names
  mutate(city_state = MAKE VARIABLE) %>% # create a city_state variable (e.g. “Baltimore, MD”)
  group_by(city) %>% 
  summarize() # summarize within cities to obtain the total number of homicides and the number of unsolved homicides (those for which the disposition is “Closed without arrest” or “Open/No arrest”).

```

For the city of Baltimore, MD, use the prop.test function to estimate the proportion of homicides that are unsolved; save the output of prop.test as an R object, apply the broom::tidy to this object and pull the estimated proportion and confidence intervals from the resulting tidy dataframe.

```{r prop.test}



```

Now run prop.test for each of the cities in your dataset, and extract both the proportion of unsolved homicides and the confidence interval for each. Do this within a “tidy” pipeline, making use of purrr::map, purrr::map2, list columns and unnest as necessary to create a tidy dataframe with estimated proportions and CIs for each city.

```{r unsolved homicides}

```

Create a plot that shows the estimates and CIs for each city – check out geom_errorbar for a way to add error bars based on the upper and lower limits. Organize cities according to the proportion of unsolved homicides.

```{r homicide plot}



```

